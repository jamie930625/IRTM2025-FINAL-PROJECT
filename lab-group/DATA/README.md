# DATA: Candidates, Queries, and Topics

This directory contains essential data resources used in our experiments, including candidate generation outputs, finalized queries, and dataset topics with relevance judgments. These files serve as both intermediate results and core inputs for the retrieval and evaluation pipeline.

## Structure

- `candidates/`: Stores the outputs of candidate generation and ranking assessment processes.
- `queries/`: Contains the finalized queries used for passage retrieval experiments.
- `topics/`: Includes test topics and corresponding relevance judgment (qrel) files for evaluation.

---

## Dataset: TREC CAsT 2022

We use the **TREC CAsT 2022 evaluation topics** as our primary dataset for conversational search experiments.

Specifically, the following files:

- [topics/2022_flatten_test_topics.json](topics/2022_flatten_test_topics.json)
- [topics/2022_test_qrels_binary.json](topics/2022_test_qrels_binary.json)

are generated by preprocessing the original topic file:

- [treccastweb/2022/2022_evaluation_topics_tree_v1.0.json](https://github.com/daltonj/treccastweb/blob/master/2022/2022_evaluation_topics_tree_v1.0.json) (obtained from the official [TREC CAsT repository](https://github.com/daltonj/treccastweb))


## Collection: MS MARCO V2 and KILT Wikipedia

1. Download the collections:

  ```bash
  wget -c https://msmarco.z22.web.core.windows.net/msmarcoranking/msmarco_v2_doc.tar
  wget -c http://dl.fbaipublicfiles.com/KILT/kilt_knowledgesource.json
  ```
  
  > **Note:** We recommend using **aria2** instead of **wget** to achieve faster download speeds.

2. Corpus Preprocessing:

We follow the preprocessing pipeline provided by the [TREC-CAsT Tools repository](https://github.com/grill-lab/trec-cast-tools).

Specifically, we use the script [corpus_processing/main.py](https://github.com/grill-lab/trec-cast-tools/blob/master/corpus_processing/Readme.md) to preprocess raw corpora from multiple sources (e.g., **KILT**, and **MS MARCO V2**).

This preprocessing step includes:
- Text cleaning
- Deduplication
- Passage chunking
- Format conversion

The processed outputs are converted into `JSONL` or `TRECWEB` formats to support downstream indexing and retrieval experiments.

3. Indexing with Pyserini:

Index the passages using Pyserini, a Python wrapper around Anserini. Java (JDK) is required as a prerequisite. After installing Pyserini, use the following command to build the index:

  ```bash
  time python -m pyserini.index \
    --collection JsonCollection \
    --generator DefaultLuceneDocumentGenerator \
    --threads 76 \
    --input collection-paragraph \
    --index index-paragraph \
    --storePositions \
    --storeDocvectors \
    --storeRaw
  ```

## Citation

### TREC CAsT 2022

```bibtex
@inproceedings{Owoicho2022TRECC2,
  title={TREC CAsT 2022: Going Beyond User Ask and System Retrieve with Initiative and Response Generation},
  author={Paul Owoicho and Jeffrey Dalton and Mohammad Aliannejadi and Leif Azzopardi and Johanne R. Trippas and Svitlana Vakulenko},
  booktitle={Text Retrieval Conference},
  year={2022}
}
```

The original TREC CAsT source code is available at: [https://github.com/daltonj/treccastweb](https://github.com/daltonj/treccastweb)